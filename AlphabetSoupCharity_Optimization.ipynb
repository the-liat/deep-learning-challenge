{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoO7ozCBvM1w"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "KT4WKa4SvM1z",
        "outputId": "c4e26172-6f44-4888-9e08-629c001b38bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1996e0d-613b-4917-b049-ac06bc09887a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1996e0d-613b-4917-b049-ac06bc09887a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1996e0d-613b-4917-b049-ac06bc09887a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1996e0d-613b-4917-b049-ac06bc09887a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd \n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h7QnaCDxvM11",
        "outputId": "b97f19b3-76de-4e81-9057-077ea8a0eeec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
              "0              T10       Independent          C1000    ProductDev   \n",
              "1               T3       Independent          C2000  Preservation   \n",
              "2               T5  CompanySponsored          C3000    ProductDev   \n",
              "3               T3  CompanySponsored          C2000  Preservation   \n",
              "4               T3       Independent          C1000     Heathcare   \n",
              "\n",
              "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
              "0   Association       1              0                      N     5000   \n",
              "1  Co-operative       1         1-9999                      N   108590   \n",
              "2   Association       1              0                      N     5000   \n",
              "3         Trust       1    10000-24999                      N     6692   \n",
              "4         Trust       1  100000-499999                      N   142590   \n",
              "\n",
              "   IS_SUCCESSFUL  \n",
              "0              1  \n",
              "1              1  \n",
              "2              0  \n",
              "3              1  \n",
              "4              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f289280-d441-480e-aa8b-be4aa46a3525\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f289280-d441-480e-aa8b-be4aa46a3525')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f289280-d441-480e-aa8b-be4aa46a3525 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f289280-d441-480e-aa8b-be4aa46a3525');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(columns=['EIN', 'NAME'])\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQW25SlavM11",
        "outputId": "dd51c146-92e2-4d4a-a0e5-3e5c3004abd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7CLr9tvvM11",
        "outputId": "d152da82-fe09-408e-eaef-92e95b1e4cbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "app_counts = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "app_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvGhOCNavM11",
        "outputId": "cf664abb-ece4-40f8-a2e6-5c8ad6d7583d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = app_counts[app_counts < 528].index.tolist()\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assessing outliers for ASK_AMT var \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# creating boxplot for the ask amount\n",
        "ask_amount = application_df['ASK_AMT'].tolist()\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.set_title('Distribution of Funding Amount Requested')\n",
        "ax1.set_ylabel('$')\n",
        "ax1.boxplot(ask_amount)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "0Wfd358FqPeT",
        "outputId": "4e05188f-aea4-443c-efe4-0b44852fbfce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine which data points are outside of the 1.5*IQR range\n",
        "quartiles = np.quantile(ask_amount,[.25,.75])\n",
        "iqr = quartiles[1]-quartiles[0]\n",
        "lower_bound = quartiles[0]-(1.5*iqr)\n",
        "upper_bound = quartiles[1]+(1.5*iqr)\n",
        "potential_outliers = []\n",
        "# potential_outliers = [potential_outliers.append(amount) if amount < lower_bound or amount > upper_bound else next for amount in ask_amount]\n",
        "\n",
        "for amount in ask_amount:\n",
        "    if amount < lower_bound or amount > upper_bound:\n",
        "        potential_outliers.append(amount)\n",
        "\n",
        "print(f\"There are {len(potential_outliers)} potential outliers out of {application_df.shape[0]} records\")\n",
        "print(f\"That is {len(potential_outliers)/application_df.shape[0]*100}% of the records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hL9f08jrSLb",
        "outputId": "d6cafcad-7159-49cc-96a5-e71aa6de6040"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 8206 potential outliers out of 34299 records\n",
            "That is 23.924895769555967% of the records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Given that there are so many potential outliers for the amount, it doesn't make sense to get rid of these outliers, \n",
        "so I'll try other optimization methods. First I'll take out the CLASSIFICATION feature (Government organization classification),\n",
        "as well as the AFFILIATION feature (Affiliated sector of industry). Intuitively these features don't seem to me like they are important, \n",
        "and they have many categories each\"\"\"\n",
        "\n",
        "# Dropping the CLASSIFICATION and AFFILIATION features and saving into new df\n",
        "application_df_reduced = application_df.drop(columns=['CLASSIFICATION', 'AFFILIATION'])\n",
        "application_df_reduced.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wA8zrTryuh1z",
        "outputId": "23d4a981-cc71-4587-9551-ddcc7c32823f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  APPLICATION_TYPE      USE_CASE  ORGANIZATION  STATUS     INCOME_AMT  \\\n",
              "0              T10    ProductDev   Association       1              0   \n",
              "1               T3  Preservation  Co-operative       1         1-9999   \n",
              "2               T5    ProductDev   Association       1              0   \n",
              "3               T3  Preservation         Trust       1    10000-24999   \n",
              "4               T3     Heathcare         Trust       1  100000-499999   \n",
              "\n",
              "  SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0                      N     5000              1  \n",
              "1                      N   108590              1  \n",
              "2                      N     5000              0  \n",
              "3                      N     6692              1  \n",
              "4                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1447d2c4-160f-4652-a92e-dde8176da7d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1447d2c4-160f-4652-a92e-dde8176da7d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1447d2c4-160f-4652-a92e-dde8176da7d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1447d2c4-160f-4652-a92e-dde8176da7d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "UnR4EivMvM13",
        "outputId": "bab0b75b-0e59-4220-bb05-8814988d7c9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                       0   \n",
              "1       1   108590              1                       0   \n",
              "2       1     5000              0                       0   \n",
              "3       1     6692              1                       0   \n",
              "4       1   142590              1                       0   \n",
              "\n",
              "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                     1                     0                    0   \n",
              "1                     0                     0                    1   \n",
              "2                     0                     0                    0   \n",
              "3                     0                     0                    1   \n",
              "4                     0                     0                    1   \n",
              "\n",
              "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                    0                    0                    0  ...   \n",
              "1                    0                    0                    0  ...   \n",
              "2                    0                    1                    0  ...   \n",
              "3                    0                    0                    0  ...   \n",
              "4                    0                    0                    0  ...   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0                  0                       0                         0   \n",
              "1                  1                       0                         0   \n",
              "2                  0                       0                         0   \n",
              "3                  0                       1                         0   \n",
              "4                  0                       0                         1   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                   0                 0                       0   \n",
              "1                   0                 0                       0   \n",
              "2                   0                 0                       0   \n",
              "3                   0                 0                       0   \n",
              "4                   0                 0                       0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0                0                  0                         1   \n",
              "1                0                  0                         1   \n",
              "2                0                  0                         1   \n",
              "3                0                  0                         1   \n",
              "4                0                  0                         1   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                         0  \n",
              "1                         0  \n",
              "2                         0  \n",
              "3                         0  \n",
              "4                         0  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23e3a109-05f6-4c42-bc8d-a485223c75b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23e3a109-05f6-4c42-bc8d-a485223c75b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23e3a109-05f6-4c42-bc8d-a485223c75b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23e3a109-05f6-4c42-bc8d-a485223c75b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_df_reduced = pd.get_dummies(application_df_reduced)\n",
        "application_df_reduced.head() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RKAt28MzvM13"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = application_df_reduced['IS_SUCCESSFUL'].values\n",
        "X = application_df_reduced.drop(columns = 'IS_SUCCESSFUL').values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ow2rBSGrvM13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2682d451-7209-4601-f36c-497952dc2a98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25724, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDVqm_eSvM13"
      },
      "source": [
        "## Compile, Train and Evaluate the Model on the DataFrame with the Reduced Features <br> \n",
        "(First Optimization Try) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCjUc6twvM14",
        "outputId": "7f9ee780-58d7-4cae-c049-b1fc46406574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 40)                1280      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                1230      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,541\n",
            "Trainable params: 2,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 =  40\n",
        "hidden_nodes_layer2 = 30\n",
        "\"\"\"I reduced the number of nodes in the first hidden layer form 80 in the initial model to 40 here\"\"\"\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DQX4Y2puvM14"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qp6yCprvM14",
        "outputId": "96ab5ea3-85d2-4814-95fe-3d16a5ff7438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 6s 4ms/step - loss: 0.6498 - accuracy: 0.6228\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.6401 - accuracy: 0.6320\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6389 - accuracy: 0.6323\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6387 - accuracy: 0.6329\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6381 - accuracy: 0.6334\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6378 - accuracy: 0.6338\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6370 - accuracy: 0.6340\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6371 - accuracy: 0.6340\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6370 - accuracy: 0.6348\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6366 - accuracy: 0.6345\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6367 - accuracy: 0.6350\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6363 - accuracy: 0.6350\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6361 - accuracy: 0.6351\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6360 - accuracy: 0.6350\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6365 - accuracy: 0.6352\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6359 - accuracy: 0.6357\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6358 - accuracy: 0.6355\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6356 - accuracy: 0.6362\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6356 - accuracy: 0.6357\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6354 - accuracy: 0.6356\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6355 - accuracy: 0.6356\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6356 - accuracy: 0.6352\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6354 - accuracy: 0.6358\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6352 - accuracy: 0.6358\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6349 - accuracy: 0.6364\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6351 - accuracy: 0.6357\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6351 - accuracy: 0.6365\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6348 - accuracy: 0.6356\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6350 - accuracy: 0.6359\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6351 - accuracy: 0.6358\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6348 - accuracy: 0.6361\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6349 - accuracy: 0.6364\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6347 - accuracy: 0.6363\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6348 - accuracy: 0.6360\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6347 - accuracy: 0.6361\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6345 - accuracy: 0.6358\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6348 - accuracy: 0.6363\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6346 - accuracy: 0.6366\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6346 - accuracy: 0.6361\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6345 - accuracy: 0.6362\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6344 - accuracy: 0.6361\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6347 - accuracy: 0.6359\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6346 - accuracy: 0.6368\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6344 - accuracy: 0.6358\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6344 - accuracy: 0.6362\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6342 - accuracy: 0.6361\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6341 - accuracy: 0.6367\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6343 - accuracy: 0.6366\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6342 - accuracy: 0.6360\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6342 - accuracy: 0.6359\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6343 - accuracy: 0.6366\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6341 - accuracy: 0.6364\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6340 - accuracy: 0.6364\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6342 - accuracy: 0.6368\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6341 - accuracy: 0.6366\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6340 - accuracy: 0.6368\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6341 - accuracy: 0.6368\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6340 - accuracy: 0.6365\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.6366\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6341 - accuracy: 0.6363\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6340 - accuracy: 0.6366\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6336 - accuracy: 0.6365\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6337 - accuracy: 0.6361\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6339 - accuracy: 0.6369\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6336 - accuracy: 0.6366\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6339 - accuracy: 0.6366\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.6364\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6338 - accuracy: 0.6365\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.6366\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.6338 - accuracy: 0.6371\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6337 - accuracy: 0.6359\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6339 - accuracy: 0.6365\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.6368\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6336 - accuracy: 0.6367\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.6364\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6336 - accuracy: 0.6368\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.6366\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6335 - accuracy: 0.6361\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6335 - accuracy: 0.6369\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6336 - accuracy: 0.6370\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.6371\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6336 - accuracy: 0.6369\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.6370\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6333 - accuracy: 0.6367\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.6370\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6333 - accuracy: 0.6368\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6333 - accuracy: 0.6370\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6332 - accuracy: 0.6368\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6335 - accuracy: 0.6370\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6332 - accuracy: 0.6372\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6333 - accuracy: 0.6373\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.6365\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6334 - accuracy: 0.6368\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6332 - accuracy: 0.6372\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6332 - accuracy: 0.6371\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6330 - accuracy: 0.6372\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6332 - accuracy: 0.6370\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6331 - accuracy: 0.6367\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6331 - accuracy: 0.6369\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6328 - accuracy: 0.6370\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY6oymMjvM14",
        "outputId": "a37eff0d-fbb3-4246-c165-a6de08ad4ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.6366 - accuracy: 0.6352 - 542ms/epoch - 2ms/step\n",
            "Loss: 0.6366212368011475, Accuracy: 0.6352186799049377\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Since the accuracy and loss are worse than the initial model, I will try other optimization methods. \n",
        "My second attempt is to add another hidden layer. But first I have to had back the features I took out and re-process the data\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "sXbpC15v0i6v",
        "outputId": "87e0b97a-feee-47cc-a324-9a406c51f8ec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Since the accuracy and loss are worse than the initial model, I will try other optimization methods. \\nMy second attempt is to add another hidden layer. But first I have to had back the features I took out and re-process the data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding Back the Removed Features and Reprocessing the Data"
      ],
      "metadata": {
        "id": "2bIRbbrtYq_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining categories into 'Other' for the CLASSIFICATION variable\n",
        "class_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "classifications_to_replace = class_counts[class_counts < 1883].index.tolist()\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "application_df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hWMMqcQWTCO",
        "outputId": "480a43cd-35b2-46f1-d403-e92ae5441798"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE             9\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION               6\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_df = pd.get_dummies(application_df)\n",
        "application_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfYPRKzEXnMk",
        "outputId": "8d65d1c8-af48-4485-e630-8fe7d86a7f24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['STATUS', 'ASK_AMT', 'IS_SUCCESSFUL', 'APPLICATION_TYPE_Other',\n",
              "       'APPLICATION_TYPE_T10', 'APPLICATION_TYPE_T19', 'APPLICATION_TYPE_T3',\n",
              "       'APPLICATION_TYPE_T4', 'APPLICATION_TYPE_T5', 'APPLICATION_TYPE_T6',\n",
              "       'APPLICATION_TYPE_T7', 'APPLICATION_TYPE_T8',\n",
              "       'AFFILIATION_CompanySponsored', 'AFFILIATION_Family/Parent',\n",
              "       'AFFILIATION_Independent', 'AFFILIATION_National', 'AFFILIATION_Other',\n",
              "       'AFFILIATION_Regional', 'CLASSIFICATION_C1000', 'CLASSIFICATION_C1200',\n",
              "       'CLASSIFICATION_C2000', 'CLASSIFICATION_C2100', 'CLASSIFICATION_C3000',\n",
              "       'CLASSIFICATION_Other', 'USE_CASE_CommunityServ', 'USE_CASE_Heathcare',\n",
              "       'USE_CASE_Other', 'USE_CASE_Preservation', 'USE_CASE_ProductDev',\n",
              "       'ORGANIZATION_Association', 'ORGANIZATION_Co-operative',\n",
              "       'ORGANIZATION_Corporation', 'ORGANIZATION_Trust', 'INCOME_AMT_0',\n",
              "       'INCOME_AMT_1-9999', 'INCOME_AMT_10000-24999',\n",
              "       'INCOME_AMT_100000-499999', 'INCOME_AMT_10M-50M', 'INCOME_AMT_1M-5M',\n",
              "       'INCOME_AMT_25000-99999', 'INCOME_AMT_50M+', 'INCOME_AMT_5M-10M',\n",
              "       'SPECIAL_CONSIDERATIONS_N', 'SPECIAL_CONSIDERATIONS_Y'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the preprocessed complete data into features and target arrays\n",
        "y = application_df['IS_SUCCESSFUL'].values\n",
        "X = application_df.drop(columns = 'IS_SUCCESSFUL').values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ],
      "metadata": {
        "id": "W8Wlvs06YUk4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "g2qxsjeaYkCS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVRLbf9mY6AB",
        "outputId": "7b7df08d-7a79-4b72-cfe2-297cf7018b49"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile, Train and Evaluate the Model with an Additional Hidden Layer <br> \n",
        "(Second Optimization Try)"
      ],
      "metadata": {
        "id": "z-gWGGch1Yh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 =  40\n",
        "hidden_nodes_layer2 = 30\n",
        "hidden_nodes_layer3 = 30\n",
        "\n",
        "nn1 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TqlTmDN1gBw",
        "outputId": "d64f34e6-218f-45b3-aac3-c8035b2ea78a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 40)                1760      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 30)                1230      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 30)                930       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,951\n",
            "Trainable params: 3,951\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "TEVHCQt72R6E"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn1.fit(X_train_scaled,y_train,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goWRNqp72c5T",
        "outputId": "487f8522-fd46-49db-c552-b0c499a877f2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 3s 2ms/step - loss: 0.5755 - accuracy: 0.7193\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5543 - accuracy: 0.7308\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5518 - accuracy: 0.7310\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7325\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7345\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5485 - accuracy: 0.7342\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5474 - accuracy: 0.7355\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7350\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5461 - accuracy: 0.7345\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7356\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7354\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7364\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7362\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7365\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7353\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7366\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7360\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7358\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7370\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7371\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7374\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7362\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7367\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7371\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7379\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7377\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7376\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7371\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7377\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7385\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7379\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7384\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7391\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7389\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7389\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7395\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.7391\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7393\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7399\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7387\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5400 - accuracy: 0.7393\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7388\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7388\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7397\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7397\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7397\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7393\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7390\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5387 - accuracy: 0.7400\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7396\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7395\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7394\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7401\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7399\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7400\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7405\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5377 - accuracy: 0.7394\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7396\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7404\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7397\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7401\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7400\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7397\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7402\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.7406\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7403\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7402\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7402\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7399\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7407\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7397\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7400\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7408\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5367 - accuracy: 0.7402\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7405\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7402\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7401\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7403\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7405\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7404\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7410\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5361 - accuracy: 0.7404\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7400\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7407\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7403\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7407\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7409\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7413\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7411\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5356 - accuracy: 0.7407\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7411\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7406\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7404\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7415\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7405\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7400\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7409\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5364 - accuracy: 0.7406\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7403\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn1.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf3z_bVx4GOR",
        "outputId": "bf649cad-214c-413a-fe73-9d6709a7772c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5564 - accuracy: 0.7265 - 433ms/epoch - 2ms/step\n",
            "Loss: 0.5564491748809814, Accuracy: 0.7265306115150452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Since the accuracy and loss are not much better than the initial model, I will try now to increase the number of epochs and change \n",
        "the activization model in the hidden layers. I'll go back to two layers, since adding another one didn't help\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Ve0exNy04ciA",
        "outputId": "2f1023ec-66c8-4fe9-c1e4-e87d272fd95c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Since the accuracy and loss are not much better than the initial model, I will try now to increase the number of epochs and change \\nthe activization model in the hidden layers. I'll go back to two layers, since adding another one didn't help\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile, Train and Evaluate the Model with Different Activation Method and More Epochs <br>\n",
        "(Third Optimization Try)"
      ],
      "metadata": {
        "id": "-yRHkpXd5BPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.compat import np_version_under1p21\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 =  40\n",
        "hidden_nodes_layer2 = 30\n",
        "\n",
        "nn2 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
        "\n",
        "# Output layer\n",
        "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGq3vjgs5O53",
        "outputId": "54beca41-ff53-4ea9-99c7-5ff385d39aa6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 40)                1760      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 30)                1230      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,021\n",
            "Trainable params: 3,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Idv5NyuI7aMw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn2.fit(X_train_scaled,y_train,epochs=400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mExHtvlZ7ef1",
        "outputId": "be8a927a-8d1f-4a69-a22e-f1f6d8cbf81c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5754 - accuracy: 0.7180\n",
            "Epoch 2/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5573 - accuracy: 0.7312\n",
            "Epoch 3/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5537 - accuracy: 0.7309\n",
            "Epoch 4/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5518 - accuracy: 0.7317\n",
            "Epoch 5/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7324\n",
            "Epoch 6/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7327\n",
            "Epoch 7/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7318\n",
            "Epoch 8/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7332\n",
            "Epoch 9/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.7339\n",
            "Epoch 10/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7340\n",
            "Epoch 11/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7354\n",
            "Epoch 12/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7345\n",
            "Epoch 13/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7343\n",
            "Epoch 14/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7348\n",
            "Epoch 15/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7351\n",
            "Epoch 16/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7358\n",
            "Epoch 17/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7360\n",
            "Epoch 18/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7365\n",
            "Epoch 19/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7368\n",
            "Epoch 20/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7378\n",
            "Epoch 21/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7364\n",
            "Epoch 22/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7358\n",
            "Epoch 23/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7365\n",
            "Epoch 24/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7364\n",
            "Epoch 25/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7383\n",
            "Epoch 26/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7374\n",
            "Epoch 27/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7375\n",
            "Epoch 28/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7381\n",
            "Epoch 29/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7369\n",
            "Epoch 30/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7378\n",
            "Epoch 31/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7385\n",
            "Epoch 32/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.7388\n",
            "Epoch 33/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7378\n",
            "Epoch 34/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7391\n",
            "Epoch 35/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7378\n",
            "Epoch 36/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7386\n",
            "Epoch 37/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7376\n",
            "Epoch 38/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7385\n",
            "Epoch 39/400\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5394 - accuracy: 0.7378\n",
            "Epoch 40/400\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5395 - accuracy: 0.7380\n",
            "Epoch 41/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7399\n",
            "Epoch 42/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7386\n",
            "Epoch 43/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7393\n",
            "Epoch 44/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7395\n",
            "Epoch 45/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7400\n",
            "Epoch 46/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7385\n",
            "Epoch 47/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5384 - accuracy: 0.7404\n",
            "Epoch 48/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7395\n",
            "Epoch 49/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7406\n",
            "Epoch 50/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7401\n",
            "Epoch 51/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7390\n",
            "Epoch 52/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7390\n",
            "Epoch 53/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7393\n",
            "Epoch 54/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7395\n",
            "Epoch 55/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7399\n",
            "Epoch 56/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7394\n",
            "Epoch 57/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7400\n",
            "Epoch 58/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7404\n",
            "Epoch 59/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7406\n",
            "Epoch 60/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7397\n",
            "Epoch 61/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7395\n",
            "Epoch 62/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7404\n",
            "Epoch 63/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7401\n",
            "Epoch 64/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7408\n",
            "Epoch 65/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7400\n",
            "Epoch 66/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7409\n",
            "Epoch 67/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7404\n",
            "Epoch 68/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7410\n",
            "Epoch 69/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7405\n",
            "Epoch 70/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7406\n",
            "Epoch 71/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7407\n",
            "Epoch 72/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5364 - accuracy: 0.7406\n",
            "Epoch 73/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7400\n",
            "Epoch 74/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7404\n",
            "Epoch 75/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7407\n",
            "Epoch 76/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7406\n",
            "Epoch 77/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7404\n",
            "Epoch 78/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7409\n",
            "Epoch 79/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7406\n",
            "Epoch 80/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7411\n",
            "Epoch 81/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7412\n",
            "Epoch 82/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7409\n",
            "Epoch 83/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7411\n",
            "Epoch 84/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7416\n",
            "Epoch 85/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7411\n",
            "Epoch 86/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7413\n",
            "Epoch 87/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7402\n",
            "Epoch 88/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7411\n",
            "Epoch 89/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5352 - accuracy: 0.7413\n",
            "Epoch 90/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7411\n",
            "Epoch 91/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7412\n",
            "Epoch 92/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7405\n",
            "Epoch 93/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7415\n",
            "Epoch 94/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7405\n",
            "Epoch 95/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7414\n",
            "Epoch 96/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7415\n",
            "Epoch 97/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5348 - accuracy: 0.7415\n",
            "Epoch 98/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7418\n",
            "Epoch 99/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7404\n",
            "Epoch 100/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7421\n",
            "Epoch 101/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7418\n",
            "Epoch 102/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7416\n",
            "Epoch 103/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7414\n",
            "Epoch 104/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7413\n",
            "Epoch 105/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7410\n",
            "Epoch 106/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7414\n",
            "Epoch 107/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7416\n",
            "Epoch 108/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7416\n",
            "Epoch 109/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7411\n",
            "Epoch 110/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7417\n",
            "Epoch 111/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7409\n",
            "Epoch 112/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7414\n",
            "Epoch 113/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7418\n",
            "Epoch 114/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5342 - accuracy: 0.7423\n",
            "Epoch 115/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7416\n",
            "Epoch 116/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7418\n",
            "Epoch 117/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7413\n",
            "Epoch 118/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7415\n",
            "Epoch 119/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7417\n",
            "Epoch 120/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7420\n",
            "Epoch 121/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7419\n",
            "Epoch 122/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5337 - accuracy: 0.7425\n",
            "Epoch 123/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7424\n",
            "Epoch 124/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7423\n",
            "Epoch 125/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7419\n",
            "Epoch 126/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7418\n",
            "Epoch 127/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7420\n",
            "Epoch 128/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7419\n",
            "Epoch 129/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7416\n",
            "Epoch 130/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5334 - accuracy: 0.7423\n",
            "Epoch 131/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7422\n",
            "Epoch 132/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7422\n",
            "Epoch 133/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7423\n",
            "Epoch 134/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7420\n",
            "Epoch 135/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7422\n",
            "Epoch 136/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7424\n",
            "Epoch 137/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7418\n",
            "Epoch 138/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7418\n",
            "Epoch 139/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5333 - accuracy: 0.7424\n",
            "Epoch 140/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7421\n",
            "Epoch 141/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7421\n",
            "Epoch 142/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7422\n",
            "Epoch 143/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7418\n",
            "Epoch 144/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7421\n",
            "Epoch 145/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7423\n",
            "Epoch 146/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7424\n",
            "Epoch 147/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7423\n",
            "Epoch 148/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7422\n",
            "Epoch 149/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7427\n",
            "Epoch 150/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7425\n",
            "Epoch 151/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7423\n",
            "Epoch 152/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7428\n",
            "Epoch 153/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7421\n",
            "Epoch 154/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7428\n",
            "Epoch 155/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5328 - accuracy: 0.7421\n",
            "Epoch 156/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7424\n",
            "Epoch 157/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7421\n",
            "Epoch 158/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7424\n",
            "Epoch 159/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7423\n",
            "Epoch 160/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7425\n",
            "Epoch 161/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7426\n",
            "Epoch 162/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7427\n",
            "Epoch 163/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7425\n",
            "Epoch 164/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7422\n",
            "Epoch 165/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7420\n",
            "Epoch 166/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7426\n",
            "Epoch 167/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7421\n",
            "Epoch 168/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7418\n",
            "Epoch 169/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7426\n",
            "Epoch 170/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7427\n",
            "Epoch 171/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7420\n",
            "Epoch 172/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7428\n",
            "Epoch 173/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7423\n",
            "Epoch 174/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7421\n",
            "Epoch 175/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7428\n",
            "Epoch 176/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7428\n",
            "Epoch 177/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7422\n",
            "Epoch 178/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7427\n",
            "Epoch 179/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7427\n",
            "Epoch 180/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7425\n",
            "Epoch 181/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7426\n",
            "Epoch 182/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7424\n",
            "Epoch 183/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7424\n",
            "Epoch 184/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7420\n",
            "Epoch 185/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7429\n",
            "Epoch 186/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7425\n",
            "Epoch 187/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7423\n",
            "Epoch 188/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7431\n",
            "Epoch 189/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7424\n",
            "Epoch 190/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7434\n",
            "Epoch 191/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7424\n",
            "Epoch 192/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7423\n",
            "Epoch 193/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7421\n",
            "Epoch 194/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7421\n",
            "Epoch 195/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7420\n",
            "Epoch 196/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7434\n",
            "Epoch 197/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7427\n",
            "Epoch 198/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7421\n",
            "Epoch 199/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7427\n",
            "Epoch 200/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7425\n",
            "Epoch 201/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7424\n",
            "Epoch 202/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7424\n",
            "Epoch 203/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7430\n",
            "Epoch 204/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7427\n",
            "Epoch 205/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5319 - accuracy: 0.7425\n",
            "Epoch 206/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7432\n",
            "Epoch 207/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7424\n",
            "Epoch 208/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7424\n",
            "Epoch 209/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7425\n",
            "Epoch 210/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7425\n",
            "Epoch 211/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7428\n",
            "Epoch 212/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7428\n",
            "Epoch 213/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5318 - accuracy: 0.7428\n",
            "Epoch 214/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7427\n",
            "Epoch 215/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7427\n",
            "Epoch 216/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7421\n",
            "Epoch 217/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7423\n",
            "Epoch 218/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7429\n",
            "Epoch 219/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7421\n",
            "Epoch 220/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7429\n",
            "Epoch 221/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7432\n",
            "Epoch 222/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7426\n",
            "Epoch 223/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7428\n",
            "Epoch 224/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7429\n",
            "Epoch 225/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7426\n",
            "Epoch 226/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7427\n",
            "Epoch 227/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7430\n",
            "Epoch 228/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7427\n",
            "Epoch 229/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7429\n",
            "Epoch 230/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5315 - accuracy: 0.7429\n",
            "Epoch 231/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7422\n",
            "Epoch 232/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7429\n",
            "Epoch 233/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7426\n",
            "Epoch 234/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7425\n",
            "Epoch 235/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7430\n",
            "Epoch 236/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7427\n",
            "Epoch 237/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7426\n",
            "Epoch 238/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5315 - accuracy: 0.7427\n",
            "Epoch 239/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7434\n",
            "Epoch 240/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7430\n",
            "Epoch 241/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7430\n",
            "Epoch 242/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7427\n",
            "Epoch 243/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7425\n",
            "Epoch 244/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7427\n",
            "Epoch 245/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7428\n",
            "Epoch 246/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5312 - accuracy: 0.7432\n",
            "Epoch 247/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7433\n",
            "Epoch 248/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7425\n",
            "Epoch 249/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7431\n",
            "Epoch 250/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7430\n",
            "Epoch 251/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7422\n",
            "Epoch 252/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7426\n",
            "Epoch 253/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7427\n",
            "Epoch 254/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7428\n",
            "Epoch 255/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7426\n",
            "Epoch 256/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7432\n",
            "Epoch 257/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7434\n",
            "Epoch 258/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7431\n",
            "Epoch 259/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7434\n",
            "Epoch 260/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7429\n",
            "Epoch 261/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7431\n",
            "Epoch 262/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7436\n",
            "Epoch 263/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7434\n",
            "Epoch 264/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7427\n",
            "Epoch 265/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7428\n",
            "Epoch 266/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7427\n",
            "Epoch 267/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7432\n",
            "Epoch 268/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7426\n",
            "Epoch 269/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7426\n",
            "Epoch 270/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7428\n",
            "Epoch 271/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5310 - accuracy: 0.7430\n",
            "Epoch 272/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7429\n",
            "Epoch 273/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7432\n",
            "Epoch 274/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7433\n",
            "Epoch 275/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7435\n",
            "Epoch 276/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7426\n",
            "Epoch 277/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7427\n",
            "Epoch 278/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7430\n",
            "Epoch 279/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5307 - accuracy: 0.7425\n",
            "Epoch 280/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7427\n",
            "Epoch 281/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7423\n",
            "Epoch 282/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7424\n",
            "Epoch 283/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7431\n",
            "Epoch 284/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7430\n",
            "Epoch 285/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7430\n",
            "Epoch 286/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7431\n",
            "Epoch 287/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7433\n",
            "Epoch 288/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7430\n",
            "Epoch 289/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7431\n",
            "Epoch 290/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7431\n",
            "Epoch 291/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7428\n",
            "Epoch 292/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7428\n",
            "Epoch 293/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7428\n",
            "Epoch 294/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7434\n",
            "Epoch 295/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7431\n",
            "Epoch 296/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5307 - accuracy: 0.7432\n",
            "Epoch 297/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7433\n",
            "Epoch 298/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7429\n",
            "Epoch 299/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7431\n",
            "Epoch 300/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7427\n",
            "Epoch 301/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7431\n",
            "Epoch 302/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7436\n",
            "Epoch 303/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7429\n",
            "Epoch 304/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5308 - accuracy: 0.7431\n",
            "Epoch 305/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7433\n",
            "Epoch 306/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7430\n",
            "Epoch 307/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7431\n",
            "Epoch 308/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7437\n",
            "Epoch 309/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7434\n",
            "Epoch 310/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7432\n",
            "Epoch 311/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7430\n",
            "Epoch 312/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5307 - accuracy: 0.7431\n",
            "Epoch 313/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7436\n",
            "Epoch 314/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7433\n",
            "Epoch 315/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7427\n",
            "Epoch 316/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7433\n",
            "Epoch 317/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7432\n",
            "Epoch 318/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7432\n",
            "Epoch 319/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7431\n",
            "Epoch 320/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7426\n",
            "Epoch 321/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5305 - accuracy: 0.7432\n",
            "Epoch 322/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7435\n",
            "Epoch 323/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7428\n",
            "Epoch 324/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7430\n",
            "Epoch 325/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7433\n",
            "Epoch 326/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7433\n",
            "Epoch 327/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7434\n",
            "Epoch 328/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7431\n",
            "Epoch 329/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5304 - accuracy: 0.7428\n",
            "Epoch 330/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7434\n",
            "Epoch 331/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7434\n",
            "Epoch 332/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7435\n",
            "Epoch 333/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7430\n",
            "Epoch 334/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7439\n",
            "Epoch 335/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7429\n",
            "Epoch 336/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7430\n",
            "Epoch 337/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5304 - accuracy: 0.7431\n",
            "Epoch 338/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7428\n",
            "Epoch 339/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7428\n",
            "Epoch 340/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7434\n",
            "Epoch 341/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7438\n",
            "Epoch 342/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7438\n",
            "Epoch 343/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7435\n",
            "Epoch 344/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7430\n",
            "Epoch 345/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5306 - accuracy: 0.7433\n",
            "Epoch 346/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7432\n",
            "Epoch 347/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7431\n",
            "Epoch 348/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7434\n",
            "Epoch 349/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7433\n",
            "Epoch 350/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7434\n",
            "Epoch 351/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7434\n",
            "Epoch 352/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7424\n",
            "Epoch 353/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7425\n",
            "Epoch 354/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7429\n",
            "Epoch 355/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7437\n",
            "Epoch 356/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7437\n",
            "Epoch 357/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7436\n",
            "Epoch 358/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7441\n",
            "Epoch 359/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7436\n",
            "Epoch 360/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7435\n",
            "Epoch 361/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7435\n",
            "Epoch 362/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5300 - accuracy: 0.7435\n",
            "Epoch 363/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7435\n",
            "Epoch 364/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7436\n",
            "Epoch 365/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7434\n",
            "Epoch 366/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7431\n",
            "Epoch 367/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7436\n",
            "Epoch 368/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7439\n",
            "Epoch 369/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7432\n",
            "Epoch 370/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5299 - accuracy: 0.7432\n",
            "Epoch 371/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7439\n",
            "Epoch 372/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7434\n",
            "Epoch 373/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7433\n",
            "Epoch 374/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7434\n",
            "Epoch 375/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7437\n",
            "Epoch 376/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7434\n",
            "Epoch 377/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7434\n",
            "Epoch 378/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5300 - accuracy: 0.7435\n",
            "Epoch 379/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7441\n",
            "Epoch 380/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7427\n",
            "Epoch 381/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7439\n",
            "Epoch 382/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7435\n",
            "Epoch 383/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7439\n",
            "Epoch 384/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7435\n",
            "Epoch 385/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7432\n",
            "Epoch 386/400\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5298 - accuracy: 0.7434\n",
            "Epoch 387/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7434\n",
            "Epoch 388/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7431\n",
            "Epoch 389/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7439\n",
            "Epoch 390/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7439\n",
            "Epoch 391/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7430\n",
            "Epoch 392/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7430\n",
            "Epoch 393/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7436\n",
            "Epoch 394/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7438\n",
            "Epoch 395/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7439\n",
            "Epoch 396/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7435\n",
            "Epoch 397/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7436\n",
            "Epoch 398/400\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5298 - accuracy: 0.7439\n",
            "Epoch 399/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7435\n",
            "Epoch 400/400\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd4RmWXyDJ9h",
        "outputId": "40c4084e-bd98-48a1-984e-cc94b0a77319"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.5587 - accuracy: 0.7251 - 565ms/epoch - 2ms/step\n",
            "Loss: 0.558726966381073, Accuracy: 0.7251312136650085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile, Train and Evaluate the Model using Automated Tuning Approach <br>\n",
        "(Fourth Optimization Try)"
      ],
      "metadata": {
        "id": "6as86IYPELr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a method that creates a new Sequential model with hyperparameter options\n",
        "def create_model(hp):\n",
        "    nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
        "    activation = hp.Choice('activation',['relu','tanh'])\n",
        "    \n",
        "    # Allow kerastuner to decide number of neurons in first layer\n",
        "    nn_model.add(tf.keras.layers.Dense(\n",
        "        units=hp.Int('first_units',\n",
        "                     min_value=20,\n",
        "                     max_value=40,\n",
        "                     step=5),\n",
        "        activation=activation,\n",
        "        input_dim=43))\n",
        "\n",
        "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
        "    for i in range(hp.Int('num_layers', 1, 5)):\n",
        "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "            min_value=10,\n",
        "            max_value=50,\n",
        "            step=10),\n",
        "            activation=activation))\n",
        "    \n",
        "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    # Set the number of epochs\n",
        "    epochs = hp.Int('epochs', 100, 200, step=10)\n",
        "\n",
        "    # Compile the model\n",
        "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
        "    \n",
        "    return nn_model"
      ],
      "metadata": {
        "id": "7_jDIN_7DMlk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner\n",
        "# Import the kerastuner library\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vCHAPoRt_0b",
        "outputId": "343b91b5-fb1d-443b-9336-5fd0b261a9ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.27.1)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the tuner\n",
        "tuner = kt.Hyperband(\n",
        "    create_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=150,\n",
        "    hyperband_iterations=2)"
      ],
      "metadata": {
        "id": "QLaDf5bFEg8W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the kerastuner search for best hyperparameters\n",
        "tuner.search(X_train_scaled,y_train,epochs=200,validation_data=(X_test_scaled,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "DrmVHKX5ExHr",
        "outputId": "117dbdf1-bf11-4719-97d5-c74db5dd717f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 138 Complete [00h 00m 29s]\n",
            "val_accuracy: 0.7273469567298889\n",
            "\n",
            "Best val_accuracy So Far: 0.7286297082901001\n",
            "Total elapsed time: 00h 22m 22s\n",
            "\n",
            "Search: Running Trial #139\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "relu              |relu              |activation\n",
            "40                |35                |first_units\n",
            "5                 |5                 |num_layers\n",
            "40                |30                |units_0\n",
            "170               |200               |epochs\n",
            "30                |30                |units_1\n",
            "40                |40                |units_2\n",
            "50                |10                |units_3\n",
            "50                |30                |units_4\n",
            "17                |17                |tuner/epochs\n",
            "6                 |6                 |tuner/initial_epoch\n",
            "4                 |4                 |tuner/bracket\n",
            "2                 |2                 |tuner/round\n",
            "0107              |0102              |tuner/trial_id\n",
            "\n",
            "Epoch 7/17\n",
            "804/804 [==============================] - 4s 3ms/step - loss: 0.5489 - accuracy: 0.7339 - val_loss: 0.5549 - val_accuracy: 0.7273\n",
            "Epoch 8/17\n",
            "782/804 [============================>.] - ETA: 0s - loss: 0.5473 - accuracy: 0.7349"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9f67858d215f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the kerastuner search for best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    216\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m                         ):\n\u001b[1;32m   2071\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Note that I ran the automization model several times with adjustments here and ther. At one point I ran it for an hour and a half with no improvement in performence. \n",
        "In this saved version, I interuupted the process after 20 min, because I didn't see significant changes\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "K-hLHG2ItPfJ",
        "outputId": "a30d658c-f926-48f7-b51c-afed74cbc3fa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Note that I ran the automization model several times with adjustments here and ther. At one point I ran it for an hour and a half with no improvement in performence. \\nIn this saved version, I interuupted the process after 20 min, because I didn't see significant changes\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best model hyperparameters\n",
        "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
        "best_hyper.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzj-posHFkXa",
        "outputId": "73912aca-a209-40a0-98e1-aacec248ed6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'first_units': 35,\n",
              " 'num_layers': 5,\n",
              " 'units_0': 30,\n",
              " 'epochs': 200,\n",
              " 'units_1': 30,\n",
              " 'units_2': 40,\n",
              " 'units_3': 10,\n",
              " 'units_4': 30,\n",
              " 'tuner/epochs': 17,\n",
              " 'tuner/initial_epoch': 6,\n",
              " 'tuner/bracket': 4,\n",
              " 'tuner/round': 2,\n",
              " 'tuner/trial_id': '0102'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate best model against full test data\n",
        "best_model = tuner.get_best_models(1)[0]\n",
        "model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X92IWT-KFsOg",
        "outputId": "608a8694-86ba-4bd9-9218-789df8b70714"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.5547 - accuracy: 0.7286 - 605ms/epoch - 2ms/step\n",
            "Loss: 0.5546852946281433, Accuracy: 0.7286297082901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export our model to HDF5 file\n",
        "best_model.save('AlphabetSoupCharity_Optimization.h5')"
      ],
      "metadata": {
        "id": "j2_H8mtV9oeg"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.-1.-1"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}